{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\User\\\\Desktop\\\\practice_OOPS\\\\STUDENT\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\User\\\\Desktop\\\\practice_OOPS\\\\STUDENT'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    preprocessor_path: Path\n",
    "    data_path: Path\n",
    "    train_arr: Path\n",
    "    test_arr: Path  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.student.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from src.student.utils.common import read_yaml, create_directories\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self, config_path = CONFIG_FILE_PATH, params_path = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_path)\n",
    "        self.params = read_yaml(params_path)\n",
    "        create_directories([self.config.artifact_root])\n",
    "\n",
    "    def get_data_transformation(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            preprocessor_path = config.preprocessor_path,\n",
    "            data_path = config.data_path,\n",
    "            train_arr = config.train_arr,\n",
    "            test_arr= config.test_arr)\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from src.exception import CustomException\n",
    "from src.logger import logging\n",
    "from src.student.utils.common import save_object\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self,config = DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_data_transformation(self):\n",
    "        try:\n",
    "            numerical_columns = [\"writing_score\", \"reading_score\"]\n",
    "            categorical_columns = [\n",
    "                \"gender\",\n",
    "                \"race_ethnicity\",\n",
    "                \"parental_level_of_education\",\n",
    "                \"lunch\",\n",
    "                \"test_preparation_course\",\n",
    "            ]\n",
    "\n",
    "            num_pipeline= Pipeline(\n",
    "                steps=[\n",
    "                (\"imputer\",SimpleImputer(strategy=\"median\")),\n",
    "                (\"scaler\",StandardScaler())\n",
    "\n",
    "                ]\n",
    "            )\n",
    "            cat_pipeline=Pipeline(\n",
    "\n",
    "                steps=[\n",
    "                (\"imputer\",SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"one_hot_encoder\",OneHotEncoder()),\n",
    "                (\"scaler\",StandardScaler(with_mean=False))\n",
    "                ]\n",
    "\n",
    "            )\n",
    "\n",
    "            preprocessor=ColumnTransformer(\n",
    "                [\n",
    "                (\"num_pipeline\",num_pipeline,numerical_columns),\n",
    "                (\"cat_pipelines\",cat_pipeline,categorical_columns)\n",
    "\n",
    "                ]\n",
    "\n",
    "            )\n",
    "\n",
    "            return preprocessor\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "        \n",
    "    def initiate_data_transformation(self):\n",
    "        try:\n",
    "            data_path = self.config.data_path\n",
    "            train_csv_path = os.path.join(data_path, 'train.csv')\n",
    "            test_csv_path = os.path.join(data_path, 'test.csv')\n",
    "            train_df = pd.read_csv(train_csv_path)\n",
    "            test_df = pd.read_csv(test_csv_path)\n",
    "            preprocessing_obj = self.get_data_transformation()\n",
    "            \n",
    "            target_column_name=\"math_score\"\n",
    "            numerical_columns = [\"writing_score\", \"reading_score\"]\n",
    "\n",
    "            input_feature_train_df=train_df.drop(columns=[target_column_name],axis=1)\n",
    "            target_feature_train_df=train_df[target_column_name]\n",
    "\n",
    "            input_feature_test_df=test_df.drop(columns=[target_column_name],axis=1)\n",
    "            target_feature_test_df=test_df[target_column_name]\n",
    "\n",
    "            input_feature_train_arr=preprocessing_obj.fit_transform(input_feature_train_df)\n",
    "            input_feature_test_arr=preprocessing_obj.transform(input_feature_test_df)\n",
    "\n",
    "            train_arr = np.c_[\n",
    "                input_feature_train_arr, np.array(target_feature_train_df)\n",
    "            ]\n",
    "            test_arr = np.c_[input_feature_test_arr, np.array(target_feature_test_df)]\n",
    "\n",
    "            save_object(file_path= self.config.preprocessor_path, obj= preprocessing_obj)\n",
    "\n",
    "            train_arr_csv_path = os.path.join(self.config.root_dir, 'train_arr.csv')\n",
    "            test_arr_csv_path = os.path.join(self.config.root_dir, 'test_arr.csv')\n",
    "\n",
    "            np.savetxt(train_arr_csv_path, train_arr, delimiter=',')\n",
    "            np.savetxt(test_arr_csv_path, test_arr, delimiter=',')\n",
    "            logging.info(\"train, test and preprocessor obj saved\")\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation()\n",
    "    data_transformation = DataTransformation(data_transformation_config)\n",
    "    data_transformation.initiate_data_transformation()\n",
    "except Exception as e:\n",
    "    raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "student",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
